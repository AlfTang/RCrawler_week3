{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WEEK 3\n",
    "* C.Y. Yen\n",
    "* Aug. @ RCrawler101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "\n",
    "* ### 五分鐘 R Crawler 復健XD\n",
    "\n",
    "* ### 知己知彼爬蟲攻防戰：特殊連線技巧 \n",
    "    1. User-Agent : 換張身份證吧 \n",
    "    2.  Referer: 籍貫正確\n",
    "    3. Cookie \n",
    "    4.  HTTPS: SSL\n",
    "    5.  o-auth: token - 登入 \n",
    "\n",
    "* ### 實用技巧閒嗑牙\n",
    "    1. 下載檔案 (例如去如期交所，OTC抓取 *.csv 或 *.zip 檔) <5+5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###1. 五分鐘 R 爬蟲復健XD\n",
    "众所周知，网络爬虫的最基本原理就是模拟HTTP协议向指定网站发送请求，从而从服务器端返回的网页源代码中抽取具有实用价值的信息（也可能下一次任务队列的地址）。这中间涉及到很多算法，根据网站不同域名，网站网页更新速度，网站结构深度，设定爬虫不同的爬取策略。爬虫可以从一些简单的网站上直接获取网页源代码，从而对网页源代码进行分析。但是对于一些需要用户登录的网站，要抓取网站当中被保护的数据具有一定的困难。今天要说就是一个从需要登录的网站上获取收保护数据的方法。\n",
    "* 心法： Crawler = Connector + Parser\n",
    "* 招式： get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 心法： Crawler = Connector + Parser\n",
    "* 例圖： connector + parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 招式： get\n",
    "* [CODE HERE]: PTT R-language 版 https://www.ptt.cc/bbs/R_Language/index.html\n",
    "\n",
    "#### 好用小工具回憶\n",
    "* Chrome developer tool\n",
    "    * Element\n",
    "    * Network\n",
    "* Xpath Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###2. 知己知彼爬蟲攻防戰：特殊連線技巧\n",
    "* 突破連線的線索藏在 head 裡 !\n",
    "* https://en.wikipedia.org/wiki/List_of_HTTP_header_fields#Requests\n",
    "* https://httpbin.org/\n",
    "* https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####  HTML 檔的 head 在幹嘛~\n",
    "* 應該說header只是HTTP 協定（電腦間溝通的黑話）的一個部分。類比就是寄信的信封格式\n",
    "    HTTP類比就是信封格式\n",
    "    網址就是地址，header 就是寫在信封上的資訊\n",
    "    寄出去的信也許會寫，這信是哪裡寄來的，誰寄的\n",
    "    來自server的回信header可能是狀態碼（200還是404呢）\n",
    "* 「頭」的部分是由 <head> 和 </head> 兩個標籤所界定，大部分用於規範和整體網頁相關的資訊，這些資訊通常不會直接呈現於網頁內。\n",
    "* 包含有： user-agent/ referer/ cookie / token  etc.\n",
    "* 如果瀏覽器希望阻擋網路爬蟲，通常會在 Head 裡設一些關卡\n",
    "* [FIG HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####第1關  User-Agent : 換張身份證吧\n",
    "* 心法\n",
    "    * 顧名思義，User-Agent 標註了你使用的瀏覽器 (Chrome/FireFox/IE)\n",
    "    * Server 據此 reponse 最適合該瀏覽器的內容給你\n",
    "    * 對手出招：擋掉不合格的 UA，因為爬蟲的 UA 通常預設為[我是爬蟲]\n",
    "<br><br>\n",
    "* 招式： 將 Request headers 上的 UA 改成正常的瀏覽器名稱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "####第1關 User-agent 打怪：<a href=\"http://buy.yungching.com.tw/region\">永慶房屋</a> \n",
    "傳送點：\n",
    "https://github.com/exilespacer/RCrawler_week3/blob/master/user-agent.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 第2關 Cookie：專用識別證\n",
    "* 心法\n",
    "    * 顧名思義，Cookie 是 .... ???\n",
    "    * 先正經一點來介紹，Cookie是 server 在 client 瀏覽器設的變數\n",
    "    * 主要是為了減緩 HTTP 設計中「無狀態」的缺陷\n",
    "    * 舉個生活化的例子，喝過五十嵐吧？\n",
    "        * session: 店員留存的飲料單\n",
    "        * cookie: 客人手上拿的點餐單，上面有 session id\n",
    "        * 領飲料的時候，客人必須出示點餐單，秀出 session_id，店員會根據 session id 拿給你對應的飲料\n",
    "    * 是否點過十八禁確認頁面？輸入帳密登入過沒有？\n",
    "    * 對方出招：擋掉無法出示合格 cookie 的 request\n",
    "* 我方招式： 將 Request header 中的 cookie 設為目前可使用的 Cookie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 第2關 Cookie 打怪：<a href=\"http://www.pixiv.net/\">Pixiv </a> 登入\n",
    "* 傳送點： https://github.com/exilespacer/RCrawler_week3/blob/master/Cookie.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####第3關 Referer： 籍貫正確\n",
    "* 心法\n",
    "    * 顧名思義，Referer 會標註你從哪裡來，也就是你上一個造訪的網站\n",
    "    * 方便統計流量來源，對搜尋引擎優化很重要\n",
    "    * 冷知識：拼錯了? <a href='https://en.wikipedia.org/wiki/HTTP_referer'>Referer / Referrer</a>\n",
    "    * 對手出招：擋掉不合格的 Referer，只回應那些符合流程的 request\n",
    "<br><br>\n",
    "* 我方招式：觀察網站，將 request header 中的 Referer 換成符合流程的網址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 第3關 Referer 打怪：<a href=\"http://www.pixiv.net/\">Pixiv </a> 抓原圖\n",
    "* 傳送點："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### HTTPS: SSL\n",
    "* 心法：例圖 http://3.bp.blogspot.com/_rLHv5b5Jcuk/TA50VxyrxUI/AAAAAAAAABc/PPoLA9dQdzI/s1600/SSL.png\n",
    "* 對方出招：\n",
    "* 我方出招：see 家葳 SSL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Token\n",
    "* 心法： o-auth: token - 登入，會過期的 cookie，權限管理\n",
    "* 對方出招：\n",
    "* 我方招式：get token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Token 範例\n",
    "[ CODE HERE\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 下回預告\n",
    "\n",
    "驗證碼 + token\n",
    "實價登錄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###2. 實用技巧閒嗑牙\n",
    "* 下載檔案\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 下載檔案範例\n",
    "[CODE HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No discussion about crawling pages from the Web can be complete without talking\n",
    "about the Robot Exclusion Protocol. This protocol provides a mechanism for Web\n",
    "server administrators to communicate their file access policies; more specifically to\n",
    "identify files that may not be accessed by a crawler. This is done by keeping a file\n",
    "named robots.txt under the root directory of the Web server (such as http:\n",
    "//www.biz.uiowa.edu/robots.txt). This file provides access policy for\n",
    "different User-agents(robots or crawlers). A User-agent value of “*” denotes a default\n",
    "policy for any crawler that does not match other User-agent values in the file. A\n",
    "number of Disallow entries may be provided for a User-agent. Any URL that starts\n",
    "with the value of a Disallow field must not be retrieved by a crawler matching the\n",
    "User-agent. When a crawler wants to retrieve a page from a Web server, it must\n",
    "first fetch the appropriate robots.txt file and make sure that the URL to be\n",
    "fetched is not disallowed. More details on this exclusion protocol can be found at\n",
    "http://www.robotstxt.org/wc/norobots.html. It is efficient to cache\n",
    "the access policies of a number of servers recently visited by the crawler. This would\n",
    "avoid accessing a robots.txt file each time you need to fetch a URL. However,\n",
    "one must make sure that cache entries remain sufficiently fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
